{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple srt file to wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# Set Google Cloud credentials (ensure the path is correct)\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"D:\\\\HIẾU\\\\plenary-agility-457810-t9-2bc80a805c4a.json\"\n",
    "\n",
    "\n",
    "input_folder = r\"C:\\Users\\Hieu Pham\\Downloads\\1\"  # input folder containing .srt files (batch processing).\n",
    "                                                   # Make sure only the required .srt files are inside this folder.\n",
    "input_language_srt = 'vi'  # language of the .srt file\n",
    "\n",
    "output_folder = input_folder\n",
    "output_voice = 'vi'  # note: distinguish between gtts and Google Cloud; gtts uses 'vi' while Google Cloud uses 'vi-VN'\n",
    "\n",
    "volume = 15\n",
    "speed = 1.5  # adjust individually; speaking rate depends on the language\n",
    "max_speed_limit = 2  # used to cap speed in case a sentence is too long for context\n",
    "\n",
    "max_duration_seconds = 50000  # milliseconds; maximum output file duration — files longer than this will be split.\n",
    "                              # Used because free gtts has limits.\n",
    "\n",
    "start_index = 0  # default is 0. Use when the video is too long and gtts splits files according to max_duration_seconds.\n",
    "                  # This index is where subtitles should start after an undesired cut. \n",
    "                  # Do not rely on the index printed to the screen, it not true. Carefully align the .srt file with the audio.\n",
    "\n",
    "model = 'gtts'  # 'gtts' or 'google-cloud'\n",
    "voice_google_cloud = 'vi-VN-Neural2-A'  # Google Cloud only\n",
    "\n",
    "MAX_WORKERS = 20  # number of threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SRT to Audio Conversion ---\n",
      "Input: C:\\Users\\Hieu Pham\\Downloads\\1, Output: C:\\Users\\Hieu Pham\\Downloads\\1, TTS: gtts\n",
      "Voice Lang: vi, Initial Speed: 1.5x, Max Speed: 2x\n",
      "Volume: 15dB, Max Chunk Dur: 50000s, Start Idx: 0\n",
      "Max Threads: 20\n",
      "---------------------------------\n",
      "\n",
      "================ PROCESSING SRT: [Vietnamese] A Simple Way to Break a Bad Habit _ Judson Brewer _ TED [DownSub.com].srt ================\n",
      "\n",
      "Submitting tasks for audio chunk 1 (SRTs up to 151) for '[Vietnamese] A Simple Way to Break a Bad Habit _ Judson Brewer _ TED [DownSub.com].srt'...\n",
      "  All 151 subtitle tasks for chunk 1 submitted. Waiting for completion...\n",
      "SUCCESS: Audio chunk 'VietnameseASimpleWaytoBreakaBadHabit_JudsonBrewer_TEDDownSubcom_chunk1_endIdx151.wav' created (Duration: 561.04s).\n",
      "\n",
      "All SRT files processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "from google.cloud import texttospeech\n",
    "from gtts import gTTS\n",
    "from dotenv import load_dotenv # Ensure you have python-dotenv installed: pip install python-dotenv\n",
    "import traceback # For detailed error reporting\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# --- Core Functions (speed_up_audio_with_ffmpeg, parse_srt, srt_time_to_milliseconds are unchanged) ---\n",
    "def speed_up_audio_with_ffmpeg(input_audio_path, output_audio_path, speed_factor):\n",
    "    \"\"\"Uses FFmpeg to change the speed of audio without altering pitch.\"\"\"\n",
    "    clamped_speed_factor = max(0.5, min(float(speed_factor), 100.0))\n",
    "    if abs(clamped_speed_factor - float(speed_factor)) > 0.01:\n",
    "        # print(f\"Warning: Requested speed {speed_factor} for FFmpeg was clamped to {clamped_speed_factor}.\")\n",
    "        pass\n",
    "\n",
    "    command = [\n",
    "        \"ffmpeg\", \"-y\", \"-i\", input_audio_path,\n",
    "        \"-filter:a\", f\"atempo={clamped_speed_factor}\",\n",
    "        \"-vn\", output_audio_path\n",
    "    ]\n",
    "    try:\n",
    "        result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"FFmpeg error ({input_audio_path}@{clamped_speed_factor}x): {e.stderr.decode()}\")\n",
    "        raise\n",
    "\n",
    "def parse_srt(srt_path):\n",
    "    with open(srt_path, 'r', encoding='utf-8') as f:\n",
    "        srt_text = f.read()\n",
    "    sections = re.split(r'\\n\\s*\\n', srt_text.strip())\n",
    "    parsed = []\n",
    "    for section in sections:\n",
    "        lines = section.strip().splitlines()\n",
    "        if len(lines) >= 3:\n",
    "            try:\n",
    "                index = int(lines[0])\n",
    "                times = lines[1]\n",
    "                start_time, end_time = times.split(' --> ')\n",
    "                text = ' '.join(lines[2:]).strip()\n",
    "                parsed.append((index, start_time, end_time, text))\n",
    "            except ValueError as e:\n",
    "                print(f\"Skipping malformed SRT section: {section}. Error: {e}\")\n",
    "    return parsed\n",
    "\n",
    "def srt_time_to_milliseconds(srt_time):\n",
    "    h, m, s_ms = srt_time.split(':')\n",
    "    s, ms = s_ms.split(',')\n",
    "    return (int(h) * 3600 + int(m) * 60 + int(s)) * 1000 + int(ms)\n",
    "\n",
    "# generate_audio_segment_with_google_tts_chunked remains the same as in the previous corrected version\n",
    "# It's responsible for a single TTS call.\n",
    "def generate_audio_segment_with_google_tts_chunked(text, option=\"gtts\", language='vi',\n",
    "                                                 speed_factor_for_google_api=1.0,\n",
    "                                                 speed_factor_for_openai_api=1.0,\n",
    "                                                 volume_db=0, temp_file_id=\"temp\",\n",
    "                                                 google_voice_name=None):\n",
    "    base_temp_mp3 = f\"temp_{temp_file_id}.mp3\"\n",
    "    if not text.strip(): return AudioSegment.silent(duration=0)\n",
    "\n",
    "    if option == \"google_cloud\":\n",
    "        client = texttospeech.TextToSpeechClient()\n",
    "        synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "        voice = texttospeech.VoiceSelectionParams(language_code=language, google_voice_name='en-US-Neural2-H', ssml_gender=texttospeech.SsmlVoiceGender.FEMALE)\n",
    "        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3, speaking_rate=speed_factor_for_google_api, volume_gain_db=volume_db)\n",
    "        try:\n",
    "            response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
    "            with open(base_temp_mp3, 'wb') as out: out.write(response.audio_content)\n",
    "        except Exception as e:\n",
    "            print(f\"Google Cloud TTS error for '{text[:30]}...': {e}\"); return AudioSegment.silent(duration=0)\n",
    "        \n",
    "    elif option == \"gtts\":\n",
    "        try:\n",
    "            tts = gTTS(text=text, lang=language, slow=False); tts.save(base_temp_mp3)\n",
    "        except Exception as e:\n",
    "            print(f\"gTTS error for '{text[:30]}...': {e}\"); return AudioSegment.silent(duration=0)\n",
    "    elif option == \"openai\":\n",
    "        try:\n",
    "            client = OpenAI()\n",
    "            clamped_openai_speed = max(0.25, min(float(speed_factor_for_openai_api), 4.0))\n",
    "            with client.audio.speech.with_streaming_response.create(model='tts-1', voice='alloy', input=text, speed=clamped_openai_speed) as response:\n",
    "                response.stream_to_file(base_temp_mp3)\n",
    "        except Exception as e:\n",
    "            print(f\"OpenAI TTS error for '{text[:30]}...': {e}\"); return AudioSegment.silent(duration=0)\n",
    "    else: raise ValueError(\"TTS Option must be 'google_cloud', 'gtts', or 'openai'.\")\n",
    "\n",
    "    segment = AudioSegment.silent(duration=0)\n",
    "    try:\n",
    "        if os.path.exists(base_temp_mp3) and os.path.getsize(base_temp_mp3) > 0:\n",
    "            segment = AudioSegment.from_mp3(base_temp_mp3)\n",
    "    except Exception as e: print(f\"Error loading MP3 '{base_temp_mp3}' for '{text[:30]}...': {e}\")\n",
    "    finally:\n",
    "        if os.path.exists(base_temp_mp3): os.remove(base_temp_mp3)\n",
    "    return segment\n",
    "\n",
    "# --- New Worker Function for Full Subtitle Processing ---\n",
    "# MÃ MỚI (Thêm google_voice_name)\n",
    "def process_subtitle_to_final_audio(\n",
    "    text, srt_idx, tts_model, language,\n",
    "    initial_speed_factor, # User's preferred initial speed\n",
    "    target_srt_duration_ms,\n",
    "    volume_db,\n",
    "    speed_limit, # Overall speed limit for FFmpeg, or API cap for API-based speed\n",
    "    temp_file_id_prefix, # Base for unique temp file names within this task\n",
    "    google_voice_name=None # <-- THÊM THAM SỐ NÀY\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Handles the entire lifecycle for one subtitle: TTS, speed adjustment, padding/truncating.\n",
    "    Returns the final AudioSegment for this subtitle.\n",
    "    \"\"\"\n",
    "    # print(f\"  Worker processing SRT Index {srt_idx} ('{text[:20]}...') Target dur: {target_srt_duration_ms}ms\")\n",
    "    # Step 1: Initial TTS Generation\n",
    "    gen_args_initial = {\n",
    "        \"text\": text, \"option\": tts_model, \"language\": language,\n",
    "        \"temp_file_id\": f\"{temp_file_id_prefix}_initial\"\n",
    "    }\n",
    "    if tts_model == \"google_cloud\":\n",
    "        gen_args_initial[\"speed_factor_for_google_api\"] = initial_speed_factor\n",
    "        gen_args_initial[\"volume_db\"] = volume_db # Google API handles volume\n",
    "        gen_args_initial[\"google_voice_name\"] = google_voice_name # <-- THÊM DÒNG NÀY\n",
    "    elif tts_model == \"openai\":\n",
    "        gen_args_initial[\"speed_factor_for_openai_api\"] = initial_speed_factor\n",
    "    # For gTTS, generate_audio_segment_with_google_tts_chunked produces 1.0x speed audio.\n",
    "\n",
    "    base_generated_segment = generate_audio_segment_with_google_tts_chunked(**gen_args_initial)\n",
    "    actual_raw_duration_ms = len(base_generated_segment)\n",
    "\n",
    "    # Adjust target_srt_duration_ms if SRT had 0ms but TTS produced audio\n",
    "    if target_srt_duration_ms <= 0 and actual_raw_duration_ms > 0:\n",
    "        target_srt_duration_ms = actual_raw_duration_ms\n",
    "    elif target_srt_duration_ms <= 0 and actual_raw_duration_ms <= 0: # Both 0 or invalid\n",
    "        return AudioSegment.silent(duration=0)\n",
    "\n",
    "    final_segment_for_processing = AudioSegment.silent(duration=0) # Initialize\n",
    "\n",
    "    # Step 2: Speed Adjustment (if needed)\n",
    "    if actual_raw_duration_ms <= 0: # TTS failed or produced empty audio\n",
    "        if target_srt_duration_ms > 0:\n",
    "            final_segment_for_processing = AudioSegment.silent(duration=target_srt_duration_ms)\n",
    "    elif tts_model == \"google_cloud\" or tts_model == \"openai\":\n",
    "        current_segment_from_api = base_generated_segment\n",
    "        api_speed_used_for_current_segment = initial_speed_factor\n",
    "\n",
    "        if actual_raw_duration_ms > target_srt_duration_ms and target_srt_duration_ms > 0:\n",
    "            required_api_speed = (actual_raw_duration_ms / target_srt_duration_ms) * api_speed_used_for_current_segment\n",
    "            api_speed_cap = 2.0\n",
    "            api_speed_floor = 0.25\n",
    "            final_api_speed_for_regen = max(api_speed_floor, min(required_api_speed, api_speed_cap))\n",
    "\n",
    "            # print(f\"    SRT {srt_idx} ({tts_model}): Initial dur {actual_raw_duration_ms}ms > target {target_srt_duration_ms}ms. Regen at {final_api_speed_for_regen:.2f}x.\")\n",
    "            regen_args = {\n",
    "                \"text\": text, \"option\": tts_model, \"language\": language,\n",
    "                \"temp_file_id\": f\"{temp_file_id_prefix}_regen\"\n",
    "            }\n",
    "            if tts_model == \"google_cloud\":\n",
    "                regen_args[\"speed_factor_for_google_api\"] = final_api_speed_for_regen\n",
    "                regen_args[\"volume_db\"] = volume_db\n",
    "                gen_args_initial[\"google_voice_name\"] = google_voice_name # <-- THÊM DÒNG NÀY\n",
    "\n",
    "            elif tts_model == \"openai\":\n",
    "                regen_args[\"speed_factor_for_openai_api\"] = final_api_speed_for_regen\n",
    "            \n",
    "            final_segment_for_processing = generate_audio_segment_with_google_tts_chunked(**regen_args)\n",
    "        else: # Audio from API is short enough or fits\n",
    "            final_segment_for_processing = current_segment_from_api\n",
    "        \n",
    "        # Truncate if still too long (e.g. API speed cap reached) or if it was just right\n",
    "        final_segment_for_processing = final_segment_for_processing[:target_srt_duration_ms]\n",
    "\n",
    "    elif tts_model == \"gtts\":\n",
    "        # base_generated_segment is at 1.0x speed. FFmpeg handles speed and respects speed_limit.\n",
    "        if target_srt_duration_ms <= 0: # Should have been caught, but defensive\n",
    "            final_segment_for_processing = base_generated_segment # Use raw 1.0x\n",
    "        else:\n",
    "            ffmpeg_speed_to_apply = 1.0\n",
    "            # If audio at initial_speed_factor fits or is shorter\n",
    "            if (actual_raw_duration_ms / initial_speed_factor) <= target_srt_duration_ms:\n",
    "                ffmpeg_speed_to_apply = initial_speed_factor\n",
    "            else: # initial_speed_factor makes it too long. Calculate speed to fit.\n",
    "                ffmpeg_speed_to_apply = actual_raw_duration_ms / target_srt_duration_ms\n",
    "            \n",
    "            # Cap by speed_limit and ensure practical minimum for atempo\n",
    "            ffmpeg_speed_to_apply = max(0.5, min(ffmpeg_speed_to_apply, speed_limit))\n",
    "\n",
    "            if abs(ffmpeg_speed_to_apply - 1.0) < 0.01: # If effectively 1.0x\n",
    "                final_segment_for_processing = base_generated_segment\n",
    "            else:\n",
    "                temp_raw_path = f\"temp_{temp_file_id_prefix}_gtts_raw.mp3\"\n",
    "                temp_sped_path = f\"temp_{temp_file_id_prefix}_gtts_sped.mp3\"\n",
    "                try:\n",
    "                    base_generated_segment.export(temp_raw_path, format=\"mp3\")\n",
    "                    # print(f\"    SRT {srt_idx} (gTTS): FFmpeg @ {ffmpeg_speed_to_apply:.2f}x from raw {actual_raw_duration_ms}ms to fit {target_srt_duration_ms}ms.\")\n",
    "                    speed_up_audio_with_ffmpeg(temp_raw_path, temp_sped_path, ffmpeg_speed_to_apply)\n",
    "                    final_segment_for_processing = AudioSegment.from_mp3(temp_sped_path)\n",
    "                except Exception as e_ffmpeg:\n",
    "                    print(f\"    Error in threaded gTTS FFmpeg for srt_idx {srt_idx}: {e_ffmpeg}. Using 1.0x audio.\")\n",
    "                    final_segment_for_processing = base_generated_segment # Fallback\n",
    "                finally:\n",
    "                    if os.path.exists(temp_raw_path): os.remove(temp_raw_path)\n",
    "                    if os.path.exists(temp_sped_path): os.remove(temp_sped_path)\n",
    "        \n",
    "        # Truncate if FFmpeg (even at speed_limit) resulted in audio longer than target\n",
    "        final_segment_for_processing = final_segment_for_processing[:target_srt_duration_ms]\n",
    "\n",
    "    # Step 3: Padding (if needed)\n",
    "    current_len = len(final_segment_for_processing)\n",
    "    if target_srt_duration_ms > current_len: # current_len can be 0 if TTS failed and target was also 0\n",
    "        silence_needed_ms = target_srt_duration_ms - current_len\n",
    "        if silence_needed_ms > 0:\n",
    "            final_segment_for_processing += AudioSegment.silent(duration=silence_needed_ms)\n",
    "    \n",
    "    # Step 4: Volume Adjustment (if applicable and not handled by API)\n",
    "    if tts_model == \"gtts\" or (tts_model == \"openai\" and volume_db != 0): # Google Cloud volume handled by API\n",
    "        if volume_db != 0 and len(final_segment_for_processing) > 0:\n",
    "            final_segment_for_processing = final_segment_for_processing + volume_db\n",
    "            \n",
    "    return final_segment_for_processing\n",
    "\n",
    "\n",
    "# split_srt_into_chunks is unchanged from the previous version\n",
    "def split_srt_into_chunks(parsed_srt, max_duration_seconds, start_index_filter=0):\n",
    "    max_duration_ms = max_duration_seconds * 1000\n",
    "    chunks = []\n",
    "    current_chunk_items = []\n",
    "    \n",
    "    first_relevant_srt_item_start_ms = None\n",
    "    if parsed_srt:\n",
    "        for srt_item_index_loop, start_time_str_loop, _, _ in parsed_srt:\n",
    "             if srt_item_index_loop >= start_index_filter:\n",
    "                 first_relevant_srt_item_start_ms = srt_time_to_milliseconds(start_time_str_loop)\n",
    "                 break\n",
    "    \n",
    "    if first_relevant_srt_item_start_ms is None and start_index_filter > 0 and parsed_srt:\n",
    "        return []\n",
    "\n",
    "    chunk_actual_start_time_ms = first_relevant_srt_item_start_ms if first_relevant_srt_item_start_ms is not None else 0\n",
    "\n",
    "    for srt_item_index, start_time_str, end_time_str, text_content in parsed_srt:\n",
    "        if srt_item_index < start_index_filter:\n",
    "            continue\n",
    "\n",
    "        start_ms = srt_time_to_milliseconds(start_time_str)\n",
    "        end_ms = srt_time_to_milliseconds(end_time_str)\n",
    "        current_item_srt_span_ms = end_ms - chunk_actual_start_time_ms\n",
    "\n",
    "        if current_item_srt_span_ms < 0: \n",
    "            print(f\"Skipping subtitle index {srt_item_index} due to inconsistent time.\")\n",
    "            continue\n",
    "        \n",
    "        if current_item_srt_span_ms > max_duration_ms and current_chunk_items:\n",
    "            chunks.append(list(current_chunk_items)) \n",
    "            current_chunk_items = [] \n",
    "            chunk_actual_start_time_ms = start_ms \n",
    "            current_item_srt_span_ms = end_ms - chunk_actual_start_time_ms \n",
    "\n",
    "        current_chunk_items.append((srt_item_index, start_ms, end_ms, text_content))\n",
    "        \n",
    "        if (end_ms - start_ms) > max_duration_ms and len(current_chunk_items) == 1:\n",
    "            chunks.append(list(current_chunk_items))\n",
    "            current_chunk_items = []\n",
    "            chunk_actual_start_time_ms = -1 \n",
    "\n",
    "    if current_chunk_items:\n",
    "        chunks.append(list(current_chunk_items))\n",
    "    return chunks\n",
    "\n",
    "# --- Main Processing Logic with Threading ---\n",
    "def srt_to_audio(srt_path, output_path_prefix, input_lang_srt, output_lang_voice,\n",
    "                 initial_speed_factor_config, volume_adjustment_db_config,\n",
    "                 max_chunk_duration_sec, speed_limit_config,\n",
    "                 processing_start_index, tts_model_config, google_voice_name_config):\n",
    "    parsed_srt = parse_srt(srt_path)\n",
    "    if not parsed_srt:\n",
    "        print(f\"No subtitles parsed from {srt_path}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    srt_chunks = split_srt_into_chunks(parsed_srt, max_chunk_duration_sec, processing_start_index)\n",
    "    output_chunk_file_idx = 1\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        for chunk_num, current_chunk_items in enumerate(srt_chunks):\n",
    "            if not current_chunk_items: continue\n",
    "\n",
    "            chunk_srt_start_ms = current_chunk_items[0][1]\n",
    "            chunk_srt_end_ms = current_chunk_items[-1][2]\n",
    "            final_audio_chunk_total_duration_ms = chunk_srt_end_ms - chunk_srt_start_ms\n",
    "            \n",
    "            if final_audio_chunk_total_duration_ms <= 0:\n",
    "                print(f\"Skipping chunk {chunk_num+1} (to {output_chunk_file_idx}) due to zero/negative SRT duration ({final_audio_chunk_total_duration_ms}ms).\")\n",
    "                continue\n",
    "\n",
    "            final_audio_chunk = AudioSegment.silent(duration=final_audio_chunk_total_duration_ms)\n",
    "            last_subtitle_index_in_chunk = current_chunk_items[-1][0]\n",
    "\n",
    "            futures_map = {} # Maps future to {srt_idx, overlay_position_ms}\n",
    "            print(f\"\\nSubmitting tasks for audio chunk {output_chunk_file_idx} (SRTs up to {last_subtitle_index_in_chunk}) for '{os.path.basename(srt_path)}'...\")\n",
    "            # print(f\"  Audio chunk SRT time: {chunk_srt_start_ms/1000:.2f}s to {chunk_srt_end_ms/1000:.2f}s (Len: {final_audio_chunk_total_duration_ms/1000:.2f}s)\")\n",
    "\n",
    "            for item_idx_in_chunk, (srt_idx, start_ms, end_ms, text) in enumerate(current_chunk_items):\n",
    "                if text.strip():\n",
    "                    task_info_for_map = {\n",
    "                        \"srt_idx\": srt_idx,\n",
    "                        \"overlay_position_ms\": start_ms - chunk_srt_start_ms,\n",
    "                        \"text_preview\": text[:20] # For easier debugging if needed\n",
    "                    }\n",
    "                    target_duration_this_subtitle = end_ms - start_ms\n",
    "\n",
    "                    future = executor.submit(\n",
    "                        process_subtitle_to_final_audio, # New worker function\n",
    "                        text=text,\n",
    "                        srt_idx=srt_idx,\n",
    "                        tts_model=tts_model_config,\n",
    "                        language=output_lang_voice,\n",
    "                        initial_speed_factor=initial_speed_factor_config,\n",
    "                        target_srt_duration_ms=target_duration_this_subtitle,\n",
    "                        volume_db=volume_adjustment_db_config,\n",
    "                        speed_limit=speed_limit_config,\n",
    "                        temp_file_id_prefix=f\"{os.path.splitext(os.path.basename(srt_path))[0]}_c{chunk_num}_s{srt_idx}\",\n",
    "                        google_voice_name=google_voice_name_config # <-- THÊM DÒNG NÀY\n",
    "                    )\n",
    "                    futures_map[future] = task_info_for_map\n",
    "                else: # Handle empty text lines in SRT - create silence directly\n",
    "                    target_dur_ms = end_ms - start_ms\n",
    "                    if target_dur_ms > 0:\n",
    "                        silent_segment = AudioSegment.silent(duration=target_dur_ms)\n",
    "                        final_audio_chunk = final_audio_chunk.overlay(\n",
    "                            silent_segment,\n",
    "                            position=(start_ms - chunk_srt_start_ms)\n",
    "                        )\n",
    "            \n",
    "            print(f\"  All {len(futures_map)} subtitle tasks for chunk {output_chunk_file_idx} submitted. Waiting for completion...\")\n",
    "            for future in as_completed(futures_map):\n",
    "                task_info = futures_map[future]\n",
    "                srt_idx_completed = task_info[\"srt_idx\"]\n",
    "                try:\n",
    "                    processed_segment_for_subtitle = future.result() # This is the fully processed audio\n",
    "                    \n",
    "                    if len(processed_segment_for_subtitle) > 0:\n",
    "                        # print(f\"    SRT Idx {srt_idx_completed} ('{task_info['text_preview']}...'): Overlaying {len(processed_segment_for_subtitle)}ms at {task_info['overlay_position_ms']}ms.\")\n",
    "                        final_audio_chunk = final_audio_chunk.overlay(\n",
    "                            processed_segment_for_subtitle,\n",
    "                            position=task_info[\"overlay_position_ms\"]\n",
    "                        )\n",
    "                except Exception as e_task_complete:\n",
    "                    print(f\"  Error in completed task result for subtitle index {srt_idx_completed} ('{task_info['text_preview']}...'): {e_task_complete}\")\n",
    "                    print(traceback.format_exc())\n",
    "\n",
    "            output_audio_path = f\"{output_path_prefix}_chunk{output_chunk_file_idx}_endIdx{last_subtitle_index_in_chunk}.wav\"\n",
    "            try:\n",
    "                if len(final_audio_chunk) > 0 :\n",
    "                    final_audio_chunk.export(output_audio_path, format=\"wav\")\n",
    "                    print(f\"SUCCESS: Audio chunk '{os.path.basename(output_audio_path)}' created (Duration: {len(final_audio_chunk)/1000:.2f}s).\")\n",
    "                else:\n",
    "                    print(f\"SKIPPED: Audio chunk '{os.path.basename(output_audio_path)}' would be empty.\")\n",
    "            except Exception as e_export:\n",
    "                print(f\"Error exporting audio chunk '{output_audio_path}': {e_export}\")\n",
    "            output_chunk_file_idx += 1\n",
    "\n",
    "def process_srt_folder(root_input_folder, root_output_folder, lang_srt, lang_voice,\n",
    "                       base_speed, vol_db, chunk_duration_s, max_spd_limit, start_idx_filter, tts_engine, google_voice_name):\n",
    "    if not os.path.exists(root_input_folder):\n",
    "        print(f\"Error: Input folder '{root_input_folder}' does not exist.\")\n",
    "        return\n",
    "    if not os.path.exists(root_output_folder):\n",
    "        os.makedirs(root_output_folder)\n",
    "        print(f\"Created output folder: '{root_output_folder}'\")\n",
    "\n",
    "    for filename in os.listdir(root_input_folder):\n",
    "        if filename.endswith('.srt'):\n",
    "            srt_file_path = os.path.join(root_input_folder, filename)\n",
    "            sanitized_filename_base = re.sub(r'[^\\w\\-_]', '', os.path.splitext(filename)[0])\n",
    "            output_filename_prefix = os.path.join(root_output_folder, sanitized_filename_base)\n",
    "            \n",
    "            print(f\"\\n================ PROCESSING SRT: {filename} ================\")\n",
    "            srt_to_audio(\n",
    "                srt_path=srt_file_path, output_path_prefix=output_filename_prefix,\n",
    "                input_lang_srt=lang_srt, output_lang_voice=lang_voice,\n",
    "                initial_speed_factor_config=base_speed, volume_adjustment_db_config=vol_db,\n",
    "                max_chunk_duration_sec=chunk_duration_s, speed_limit_config=max_spd_limit,\n",
    "                processing_start_index=start_idx_filter, tts_model_config=tts_engine,\n",
    "                google_voice_name_config=google_voice_name # <-- THÊM DÒNG NÀY\n",
    "            )\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(input_folder):\n",
    "        os.makedirs(input_folder)\n",
    "    if not os.listdir(input_folder):\n",
    "        dummy_srt_path = os.path.join(input_folder, \"dummy_test.srt\")\n",
    "        with open(dummy_srt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"1\\n00:00:01,000 --> 00:00:03,500\\nĐây là một câu ví dụ đầu tiên.\\n\\n\")\n",
    "            f.write(\"2\\n00:00:04,000 --> 00:00:06,000\\nCâu này là câu thứ hai để kiểm tra.\\n\\n\")\n",
    "            f.write(\"3\\n00:00:06,500 --> 00:00:10,000\\nVà đây là một câu dài hơn một chút để thử nghiệm việc điều chỉnh tốc độ giọng nói cho phù hợp.\\n\\n\")\n",
    "            f.write(\"4\\n00:00:10,500 --> 00:00:11,500\\nNgắn.\\n\")\n",
    "        print(f\"Created dummy SRT: {dummy_srt_path}\")\n",
    "\n",
    "    print(f\"--- SRT to Audio Conversion ---\")\n",
    "    print(f\"Input: {input_folder}, Output: {output_folder}, TTS: {model}\")\n",
    "    print(f\"Voice Lang: {output_voice}, Initial Speed: {speed}x, Max Speed: {max_speed_limit}x\")\n",
    "    print(f\"Volume: {volume}dB, Max Chunk Dur: {max_duration_seconds}s, Start Idx: {start_index}\")\n",
    "    print(f\"Max Threads: {MAX_WORKERS}\")\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "    process_srt_folder(\n",
    "        root_input_folder=input_folder, root_output_folder=output_folder,\n",
    "        lang_srt=input_language_srt, lang_voice=output_voice, base_speed=speed,\n",
    "        vol_db=volume, chunk_duration_s=max_duration_seconds, max_spd_limit=max_speed_limit,\n",
    "        start_idx_filter=start_index, tts_engine=model, google_voice_name=voice_google_cloud # <-- THÊM DÒNG NÀY\n",
    "    )\n",
    "    print(\"\\nAll SRT files processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
